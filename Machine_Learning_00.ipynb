{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zietho/machine-learning/blob/master/Machine_Learning_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALaX-9cbFa-K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqgrEVyNFa-U"
   },
   "source": [
    "# Data Set 1: sentiment140\n",
    "\n",
    "Abstract: This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment. <sup>1</sup>\n",
    "\n",
    "<sup>1</sup> https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-St4Z2iNg3ir"
   },
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('datasets/sentiment/training.1600000.processed.noemoticon.csv', encoding='latin_1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "rAcHwU4_lCqL",
    "outputId": "29f41390-11df-45c5-82e7-aa66ea08313b"
   },
   "outputs": [],
   "source": [
    "df_sentiment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1524
    },
    "colab_type": "code",
    "id": "6nrVVcP_gDkR",
    "outputId": "fbb15579-4594-45c3-d835-ec6c5e514ffe"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "    '''\n",
    "    weekday extraction 1min\n",
    "    '''\n",
    "    def funcapply(x):\n",
    "        return x[0:3]\n",
    "\n",
    "    df['weekday'] = df['date'].apply(lambda x: funcapply(x))\n",
    "\n",
    "    '''\n",
    "    parse time to pandas datetime takes 5 minutes\n",
    "    from datetime import datetime\n",
    "    d = datetime.strptime('Thu Apr 23 13:38:19 +0000 2009','%a %b %d %H:%M:%S %z %Y').strftime('%Y-%m-%d %H:%M:%S');\n",
    "    '''\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n",
    "  \n",
    "df_sentiment = preprocess(df_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MjRT_a_V7oLM",
    "outputId": "80d7b0f8-e64f-4813-8c09-2eb6e5d78bc0"
   },
   "outputs": [],
   "source": [
    "df_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "5LbQN5fn7q2f",
    "outputId": "3a7a57f5-aa90-45ae-a896-a77b355e19b4"
   },
   "outputs": [],
   "source": [
    "df_sentiment.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cO0iGmWa8Cxt"
   },
   "outputs": [],
   "source": [
    "df_sentiment.columns = ['label', 'id', 'timestamp', 'query_type', 'username', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JmYSAX727ugl",
    "outputId": "94e9aa41-13ea-4102-db0f-dd31c122b8a4"
   },
   "outputs": [],
   "source": [
    "df_sentiment['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GgzCUoEx8S5R",
    "outputId": "f1cd71ed-baf1-4eb9-bce9-52c3630a8c98"
   },
   "outputs": [],
   "source": [
    "df_sentiment['query_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhnyJ9sQFa-o"
   },
   "source": [
    "# Data Set 1: OPPORTUNITY Activity Recognition Dataset\n",
    "\n",
    "Abstract: \"The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). <sup>1</sup>\n",
    "\n",
    "<sup>1</sup> https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "gYX8ytuSSpg6",
    "outputId": "d2e14e5e-d359-46af-e143-cd7c19c33f2d"
   },
   "source": [
    "# activity of daily living (ADL)\n",
    "Read in activity of daily living (ADL) for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8704
    },
    "colab_type": "code",
    "id": "FUoaE5eIXrTd",
    "outputId": "45a93522-3153-4e11-de37-e2d5f7a99ea8"
   },
   "outputs": [],
   "source": [
    "# read in column names\n",
    "opportunity_cols = dict()\n",
    "opportunity_cols_txt = open(\"datasets/opportunity/column_names.txt\", \"r\")\n",
    "\n",
    "for line in opportunity_cols_txt:\n",
    "\n",
    "    if re.search('Column',line) != None:\n",
    "        col_id = re.search('Column: (\\S*) ',line).group(1)\n",
    "        opportunity_cols[col_id] = dict()\n",
    "        opportunity_cols[col_id]['name'] = re.search('Column: \\S* (\\S*)',line).group(1)\n",
    "\n",
    "        if re.search('Column: \\S* \\S* \\S*',line) != None:\n",
    "            opportunity_cols[col_id]['sensor'] = re.search('Column: \\S* \\S* (\\S*)',line).group(1)\n",
    "            opportunity_cols[col_id]['sensor_axis'] = re.search(' (\\S*);',line).group(1)\n",
    "            opportunity_cols[col_id]['value_type'] = re.search('value = (.*),',line).group(1)\n",
    "            opportunity_cols[col_id]['unit'] = re.search('unit =(.*)$',line).group(1)\n",
    "            \n",
    "opportunity_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list()\n",
    "for key, column in opportunity_cols.items():\n",
    "    col_names.append(key+\"_\"+column.get('name'))\n",
    "col_names.insert(0,'0_User')\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "oqO1Zom-S0Qs",
    "outputId": "71f8505a-ca31-4b7a-fb03-1c2880a8a280"
   },
   "outputs": [],
   "source": [
    "adl_filename_mask = 'S{}-ADL{}.dat'\n",
    "drill_filename_mask = 'S{}-Drill.dat'\n",
    "df_opportunity_adl = pd.DataFrame()\n",
    "df_opportunity_drill = pd.DataFrame()\n",
    "\n",
    "for user_idx in range(1,5):\n",
    "    for run in range (1,6):\n",
    "        path = 'datasets/opportunity/'+adl_filename_mask.format(user_idx, run)\n",
    "        df_partial_adl = pd.read_csv(path, header=None, sep='\\s')\n",
    "        df_partial_adl.insert(0,'User',user_idx)\n",
    "        df_opportunity_adl = df_opportunity_adl.append(df_partial_adl) \n",
    "    \n",
    "    path = 'datasets/opportunity/'+adl_filename_mask.format(user_idx, run)\n",
    "    df_partial_drill = pd.read_csv(path, header=None, sep='\\s')\n",
    "    df_partial_drill.insert(0,'User',user_idx)\n",
    "    df_opportunity_drill = df_opportunity_drill.append(df_partial_adl)\n",
    "\n",
    "print(df_opportunity_adl.shape)\n",
    "\n",
    "#df_adl = pd.read_csv('drive/My Drive/University/Data Science/Machine Learning/datasets/opportunity/S1-ADL1.dat', encoding='latin_1', header=None, sep='\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoiEAWOMXp3E"
   },
   "outputs": [],
   "source": [
    "df_opportunity_adl.columns = col_names\n",
    "#df_opportunity_drill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "KIXW9NALTHHf",
    "outputId": "5bee476f-9eb9-4c0d-a859-97a1e8e75814"
   },
   "outputs": [],
   "source": [
    "df_adl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXWlm6e7TI_s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Machine-Learning-00.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
